{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import folium\n",
    "import plotly_express as px\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "import shapefile\n",
    "from datetime import datetime as dt\n",
    "from sentinelhub import CRS, BBox, DataCollection, SentinelHubCatalog, SHConfig\n",
    "from sentinelhub.aws import AwsDownloadClient\n",
    "\n",
    "\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import yaml\n",
    "# open shape files for Cameroon\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file for credentials\n",
    "PATH = '/Users/noeliaotero/Documents/Geo_analysis/'\n",
    "# Read YAML file\n",
    "with open(PATH + \"credentials.yml\", 'r') as stream:\n",
    "    credentials_conf = yaml.safe_load(stream)\n",
    "with open(PATH + \"config_sentinel.yml\", 'r') as stream:\n",
    "    s_conf = yaml.safe_load(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shafile_file = \"/Users/noeliaotero/Documents/Geo_analysis/cmr/cmr.shp\"\n",
    "sh_cmr = gpd.read_file(\"/Users/noeliaotero/Documents/Geo_analysis/cmr/cmr.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geojson_data = shapefile.Reader(shafile_file).__geo_interface__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_cmr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# connect to the API\n",
    "api = SentinelAPI(credentials_conf['user'], credentials_conf['password'], 'https://apihub.copernicus.eu/apihub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = geojson_to_wkt(read_geojson(s_conf['footprint_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = api.query(footprint,\n",
    "                     date = (date(2020,1,1),date(2020,1,10)),\n",
    "                     platformname = s_conf['platformname'],\n",
    "                     processinglevel = s_conf['processinglevel'],\n",
    "                     cloudcoverpercentage = (0, 20))\n",
    "# GeoPandas GeoDataFrame with the metadata of the scenes and the footprints as geometries\n",
    "images_df = api.to_geodataframe(products)\n",
    "\n",
    "# GeoJSON FeatureCollection containing footprints and metadata of the scenes\n",
    "# api.to_geojson(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(images_df)>1):\n",
    "    print(f\"Number of products available: {len(images_df)}\")\n",
    "    print(f\"Downloading product: {images_df.head(s_conf['download_index'])['title']}\")\n",
    "\n",
    "    # Select and download product to data directory.\n",
    "    images_df = images_df.head(s_conf['download_index'])  # Get desired product based on selected index.\n",
    "    cwd = os.getcwd()  # remember current work directory (CWD).\n",
    "    os.chdir(s_conf['data_dir'])  # Change directory.\n",
    "    api.download_all(products)\n",
    "    #api.download_all(images_df.index)  # Download product. Needs '.index' as it cannot download df directly.\n",
    "    os.chdir(cwd)  # Return to project directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the files downloaded\n",
    "from utils import * \n",
    "unzip(s_conf) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the tiff files must be created \n",
    "# https://medium.com/analytics-vidhya/two-ways-of-extracting-points-of-interest-from-sentinel-2a-data-baa124b1ed92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"B02\", \"B03\", \"B04\", \"B08\", \"B8A\", \"B11\", \"B12\"]\n",
    "resolutions = [\"R10m\", \"R10m\", \"R10m\", \"R10m\", \"R20m\", \"R20m\", \"R20m\"]\n",
    "bands_and_resolutions = list(zip(bands, resolutions))\n",
    "\n",
    "target_dim = (516, 516) # reduce dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = []\n",
    "for x in os.listdir(s_conf['data_dir']):\n",
    "    if x.endswith('SAFE'):\n",
    "        print(x)\n",
    "        date = x.split(\"_\")[2].split(\"T\")[0]\n",
    "        src_data_dir = glob.glob(os.path.join(s_conf['data_dir'], x, \"GRANULE/*/IMG_DATA\"))[0]\n",
    "        data_dirs.append((date, src_data_dir))\n",
    "\n",
    "data_dirs = sorted(data_dirs, key=lambda x: x[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_root_data_dir = '/Users/noeliaotero/Documents/Geo_analysis/data/tiff/'\n",
    "os.mkdir(tiff_root_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to check (not working properly now)\n",
    "for date, src_data_dir in data_dirs:\n",
    "    tiff_file = os.path.join(tiff_root_data_dir, date + \".tiff\")\n",
    "    \n",
    "    if os.path.exists(tiff_file):\n",
    "      \n",
    "        continue\n",
    "    \n",
    "    tiff_file = None\n",
    "    \n",
    "    for i, (band, resolution) in enumerate(bands_and_resolutions, start=1):\n",
    "        band_file = glob.glob(os.path.join(src_data_dir, resolution, \"*_\" + band + \"_*.jp2\"))[0]\n",
    "        \n",
    "        band_f = rasterio.open(band_file, driver=\"JP2OpenJPEG\")\n",
    "        band_data = band_f.read(1)\n",
    "\n",
    "        if band_data.shape[0] < target_dim[0] and band_data.shape[1] < target_dim[1]:\n",
    "            print(\"Extrapolating\", band_data.shape, \"to\", target_dim)\n",
    "            band_data = extrapolate(band_data, target_dim).astype(band_f.dtypes[0])\n",
    "            \n",
    "        if tiff_file is None:  \n",
    "            profile = band_f.profile\n",
    "            profile.update(driver=\"Gtiff\", count=len(bands_and_resolutions))\n",
    "            tiff_file = MemoryFile().open(**profile)\n",
    "            \n",
    "        #print(\"Writing band {} for date {}\".format(band, date))\n",
    "        tiff_file.write(band_data, i)\n",
    "        \n",
    "        band_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyRem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e7de3e693bcf9677b894e3bb1bb536a1cbf15f683f2874b8c3b5668889eb51a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
